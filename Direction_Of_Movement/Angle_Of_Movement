import cv2
import numpy as np
from PIL import Image
import time
import dlib
import imutils

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("Data/shape_predictor_68_face_landmarks.dat")
timer1 = 0

def draw_annotation_box(img, rotation_vector, translation_vector, camera_matrix, color=(255, 255, 0), line_width=2):
    """Draw a 3D box as annotation of pose"""
    point_3d = []
    dist_coeffs = np.zeros((4, 1))
    rear_size = 1
    rear_depth = 0
    point_3d.append((-rear_size, -rear_size, rear_depth))
    point_3d.append((-rear_size, rear_size, rear_depth))
    point_3d.append((rear_size, rear_size, rear_depth))
    point_3d.append((rear_size, -rear_size, rear_depth))
    point_3d.append((-rear_size, -rear_size, rear_depth))

    front_size = img.shape[1]
    front_depth = front_size * 2
    point_3d.append((-front_size, -front_size, front_depth))
    point_3d.append((-front_size, front_size, front_depth))
    point_3d.append((front_size, front_size, front_depth))
    point_3d.append((front_size, -front_size, front_depth))
    point_3d.append((-front_size, -front_size, front_depth))
    point_3d = np.array(point_3d, dtype=np.float).reshape(-1, 3)

    # Map to 2d img points
    (point_2d, _) = cv2.projectPoints(point_3d,
                                      rotation_vector,
                                      translation_vector,
                                      camera_matrix,
                                      dist_coeffs)
    point_2d = np.int32(point_2d.reshape(-1, 2))

    # # Draw all the lines
    #cv2.polylines(img, [point_2d], True, color, line_width, cv2.LINE_AA)
    k = (point_2d[5] + point_2d[8]) // 2
    # cv2.line(img, tuple(point_2d[1]), tuple(
    #    point_2d[6]), color, line_width, cv2.LINE_AA)
    # cv2.line(img, tuple(point_2d[2]), tuple(
    #     point_2d[7]), color, line_width, cv2.LINE_AA)
    # cv2.line(img, tuple(point_2d[3]), tuple(
    #     point_2d[8]), color, line_width, cv2.LINE_AA)

    return (point_2d[2], k)

cap = cv2.VideoCapture(0)

while True:
    _ , im = cap.read()

    #im = imutils.resize(im, width=900, height=600)

    im = cv2.flip(im, 1)
    #im = cv2.resize(im, (400, 300))

    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)

    size = im.shape

    faces = detector(gray)
    for face in faces:
        x1 = face.left()
        y1 = face.top()
        x2 = face.right()
        y2 = face.bottom()

        x = face.left()
        y = face.top()
        w = face.right() - x
        h = face.bottom() - y

        cv2.rectangle(im, (x1, y1), (x2, y2), (0, 255, 0), 3)

        landmarks = predictor(gray, face)
        print (landmarks.part(1).x)
        print (landmarks.part(1).y)

        # for n in range(0, 68):
        #     x = landmarks.part(n).x
        #     y = landmarks.part(n).y
        #     cv2.circle(im, (x, y), 4, (255, 0, 0), -1)

    # 2D image points. If you change the image, you need to change vector
        image_points = np.array([
            (landmarks.part(30).x, landmarks.part(30).y),  # Nose tip

            (landmarks.part(8).x, landmarks.part(8).y),  # Chin

            (landmarks.part(36).x, landmarks.part(36).y),  # Left eye left corner

            (landmarks.part(45).x, landmarks.part(45).y),  # Right eye right corne

            (landmarks.part(48).x, landmarks.part(48).y),  # Left Mouth corner

            (landmarks.part(54).x, landmarks.part(54).y)  # Right mouth corner

        ], dtype="double")



        # 3D model points.
        model_points = np.array([

            (0.0, 0.0, 0.0),  # Nose tip

            (0.0, -330.0, -65.0),  # Chin

            (-225.0, 170.0, -135.0),  # Left eye left corner

            (225.0, 170.0, -135.0),  # Right eye right corne

            (-150.0, -150.0, -125.0),  # Left Mouth corner

            (150.0, -150.0, -125.0)  # Right mouth corner

        ])

        # Camera internals

        focal_length = size[1]

        center = (size[1] / 2, size[0] / 2)

        camera_matrix = np.array(
            [[focal_length, 0, center[0]],

             [0, focal_length, center[1]],

             [0, 0, 1]], dtype="double"
        )

        #print ("Camera Matrix :\n {0}".format(camera_matrix))

        dist_coeffs = np.zeros((4, 1))  # Assuming no lens distortion

        (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs,
                                                                      flags = cv2.SOLVEPNP_ITERATIVE)

        #print ("Rotation Vector:\n {0}".format(rotation_vector))

        #print ("Translation Vector:\n {0}".format(translation_vector))

        # Project a 3D point (0, 0, 1000.0) onto the image plane.

        # We use this to draw a line sticking out of the nose

        (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector,
                                                         camera_matrix, dist_coeffs)

        for p in image_points:
            cv2.circle(im, (int(p[0]), int(p[1])), 3, (0, 0, 255), -1)

        p1 = (int(image_points[0][0]), int(image_points[0][1]))
        p2 = (int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))
        x1, x2 = draw_annotation_box(im, rotation_vector, translation_vector, camera_matrix)

        cv2.line(im, p1, p2, (255, 0, 0), 2)
        #cv2.line(im, tuple(x1), tuple(x2), (255, 255, 0), 2)
        
        m = p2[0] - p1[0]

        if m > 350 or m < -350:
            timeer1 += 1
            if timeer1 < 3:
                cv2.putText(im, "Warning", (x, y + h), cv2.FONT_HERSHEY_SIMPLEX, 0.90, (0, 255, 0), 2)
                print ("Warning")
            if timeer1 > 3:
                cv2.putText(im, "Cheating", (x, y + h), cv2.FONT_HERSHEY_SIMPLEX, 0.90, (0, 255, 0), 2)
                print ("Cheatimg")
                timeer1 = 0
        else:
            timeer1 = 0

            # print('div by zero error')
        cv2.putText(im, str(m), tuple(p1), cv2.FONT_HERSHEY_SIMPLEX, 2, (128, 255, 255), 3)
        #cv2.putText(im, str(ang2), tuple(x1), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 128), 3)

        # Display image
        cv2.imshow("Output", im)
        time.sleep(0.5)

    key = cv2.waitKey(1)
    if key == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
